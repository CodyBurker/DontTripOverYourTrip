{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (4.16.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: filelock in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from transformers) (3.5.0)\n",
      "Requirement already satisfied: requests in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from transformers) (0.11.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from transformers) (2022.1.18)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: sacremoses in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from transformers) (0.0.47)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from requests->transformers) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: joblib in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: six in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from sacremoses->transformers) (8.0.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: huggingface_hub in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (0.4.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from huggingface_hub) (21.3)\n",
      "Requirement already satisfied: filelock in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from huggingface_hub) (3.5.0)\n",
      "Requirement already satisfied: tqdm in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from huggingface_hub) (4.62.3)\n",
      "Requirement already satisfied: pyyaml in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from huggingface_hub) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from huggingface_hub) (4.1.1)\n",
      "Requirement already satisfied: requests in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from huggingface_hub) (2.27.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from packaging>=20.9->huggingface_hub) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from requests->huggingface_hub) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from requests->huggingface_hub) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from requests->huggingface_hub) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from requests->huggingface_hub) (2.0.12)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: torch in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (1.10.2)\n",
      "Requirement already satisfied: torchvision in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (0.11.3)\n",
      "Requirement already satisfied: torchaudio in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (0.10.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from torch) (4.1.1)\n",
      "Requirement already satisfied: numpy in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages (from torchvision) (9.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers\n",
    "! pip install huggingface_hub\n",
    "! pip install torch torchvision torchaudio\n",
    "# install AWS packages\n",
    "! pip install boto3\n",
    "! pip install sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfc7876d88f647f980a3a60fe8eda8c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/360 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c9469b65a4a4c789fe29deda7e29089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "854be04ea15346c8a42b48af05df6fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/695k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f76e1d5ecb14106abe601187c6512b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2acdb41e0ca94e4c90b9e89dc524404e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03de2dcac5f844e6954d899409c3d333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/255M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[[{'label': 'LABEL_0', 'score': 0.0031421473249793053},\n",
       "  {'label': 'LABEL_1', 'score': 0.9968578815460205}]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test pre-trained model\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import TextClassificationPipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"rwang5688/distilbert-base-uncased-finetuned-sst2\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"rwang5688/distilbert-base-uncased-finetuned-sst2\")\n",
    "\n",
    "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=True)\n",
    "pipe(\"I love Amazon SageMaker Studio Lab!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set profile name as opposed to entering credentials\n",
    "profile_name = 'default'\n",
    "region_name = 'us-west-2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Endpoints': [{'EndpointName': 'sst2-text-classification-ep-2022-10-31-17-33-28', 'EndpointArn': 'arn:aws:sagemaker:us-west-2:662235870471:endpoint/sst2-text-classification-ep-2022-10-31-17-33-28', 'CreationTime': datetime.datetime(2022, 10, 31, 11, 6, 40, 584000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2022, 10, 31, 11, 8, 46, 153000, tzinfo=tzlocal()), 'EndpointStatus': 'InService'}], 'ResponseMetadata': {'RequestId': 'ac2a2c93-9411-4ae6-a650-03b0f05600b3', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'ac2a2c93-9411-4ae6-a650-03b0f05600b3', 'content-type': 'application/x-amz-json-1.1', 'content-length': '293', 'date': 'Fri, 11 Nov 2022 03:55:54 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# get and test sagemaker client\n",
    "import boto3 \n",
    "session = boto3.Session(profile_name=profile_name)\n",
    "sm_client = session.client('sagemaker', region_name=region_name)\n",
    "response = sm_client.list_endpoints()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sst2-text-classification-model-2022-10-31-17-33-28\n",
      "sst2-text-classification-epc-2022-10-31-17-33-28\n",
      "sst2-text-classification-ep-2022-10-31-17-33-28\n"
     ]
    }
   ],
   "source": [
    "# set model name and endpoint configuration name\n",
    "import time\n",
    "ml_model_name = \"sst2-text-classification\"\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "model_name = ml_model_name + '-model' + timestamp\n",
    "endpoint_config_name = ml_model_name + '-epc' + timestamp\n",
    "endpoint_name = ml_model_name + '-ep' + timestamp\n",
    "print(model_name)\n",
    "print(endpoint_config_name)\n",
    "print(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set sagemaker execution role\n",
    "import sagemaker\n",
    "# create a sagemaker execution role via the AWS SageMaker console, then paste in the arn here\n",
    "role = 'arn:aws:iam::662235870471:role/service-role/AmazonSageMaker-ExecutionRole-20221015T100906'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-inference:1.9-transformers4.12-cpu-py38-ubuntu20.04\n",
      "{'Image': '763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-inference:1.9-transformers4.12-cpu-py38-ubuntu20.04', 'Mode': 'SingleModel', 'Environment': {'HF_MODEL_ID': 'rwang5688/distilbert-base-uncased-finetuned-sst2', 'HF_TASK': 'text-classification', 'SAGEMAKER_CONTAINER_LOG_LEVEL': '20', 'SAGEMAKER_REGION': 'us-west-2'}}\n",
      "{'ModelArn': 'arn:aws:sagemaker:us-west-2:662235870471:model/sst2-text-classification-model-2022-10-31-17-33-28', 'ResponseMetadata': {'RequestId': '6d73564a-16b4-4030-a71e-75c887dde213', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '6d73564a-16b4-4030-a71e-75c887dde213', 'content-type': 'application/x-amz-json-1.1', 'content-length': '112', 'date': 'Mon, 31 Oct 2022 18:00:20 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# see deep learning containers (DLC) available images here:\n",
    "# https://github.com/aws/deep-learning-containers/blob/master/available_images.md \n",
    "model_image_url=\"763104351884.dkr.ecr.\"+region_name+\".amazonaws.com/\"+\\\n",
    "                \"huggingface-pytorch-inference:1.9-transformers4.12-cpu-py38-ubuntu20.04\"\n",
    "print(model_image_url)\n",
    "\n",
    "# set container config\n",
    "container_config = {\n",
    "    'Image': model_image_url,\n",
    "    'Mode': 'SingleModel',\n",
    "    'Environment': {\n",
    "        'HF_MODEL_ID': 'rwang5688/distilbert-base-uncased-finetuned-sst2',\n",
    "        'HF_TASK' : 'text-classification',\n",
    "        'SAGEMAKER_CONTAINER_LOG_LEVEL' : '20',\n",
    "        'SAGEMAKER_REGION' : region_name\n",
    "    }\n",
    "}\n",
    "print(container_config)\n",
    "\n",
    "# create model\n",
    "# ... models console: https://console.aws.amazon.com/sagemaker/home?#/models\n",
    "response = sm_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    PrimaryContainer=container_config,\n",
    "    ExecutionRoleArn=role, \n",
    "    EnableNetworkIsolation=False\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EndpointConfigArn': 'arn:aws:sagemaker:us-west-2:662235870471:endpoint-config/sst2-text-classification-epc-2022-10-31-17-33-28', 'ResponseMetadata': {'RequestId': '1a499d7f-cc39-4bcb-9a3d-44c19663066f', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '1a499d7f-cc39-4bcb-9a3d-44c19663066f', 'content-type': 'application/x-amz-json-1.1', 'content-length': '129', 'date': 'Mon, 31 Oct 2022 18:06:09 GMT'}, 'RetryAttempts': 0}}\n",
      "Endpoint configuration name: sst2-text-classification-epc-2022-10-31-17-33-28\n",
      "Endpoint configuration arn:  arn:aws:sagemaker:us-west-2:662235870471:endpoint-config/sst2-text-classification-epc-2022-10-31-17-33-28\n"
     ]
    }
   ],
   "source": [
    "# create endpoint config\n",
    "# ... endpoint configs console: https://console.aws.amazon.com/sagemaker/home?#/endpointConfig\n",
    "endpoint_config_response = sm_client.create_endpoint_config(\n",
    "   EndpointConfigName=endpoint_config_name,\n",
    "   ProductionVariants=[\n",
    "        {\n",
    "            \"ModelName\": model_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "            \"ServerlessConfig\": {\n",
    "                # Specify MemorySizeInMB and MaxConcurrency in the serverless config object\n",
    "                \"MemorySizeInMB\": 3072,\n",
    "                \"MaxConcurrency\": 10\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(endpoint_config_response)\n",
    "\n",
    "print('Endpoint configuration name: {}'.format(endpoint_config_name))\n",
    "print('Endpoint configuration arn:  {}'.format(endpoint_config_response['EndpointConfigArn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EndpointArn': 'arn:aws:sagemaker:us-west-2:662235870471:endpoint/sst2-text-classification-ep-2022-10-31-17-33-28', 'ResponseMetadata': {'RequestId': '5a177b65-0ff5-445b-a7c6-0e621533a15b', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '5a177b65-0ff5-445b-a7c6-0e621533a15b', 'content-type': 'application/x-amz-json-1.1', 'content-length': '115', 'date': 'Mon, 31 Oct 2022 18:06:39 GMT'}, 'RetryAttempts': 0}}\n",
      "Endpoint name: sst2-text-classification-ep-2022-10-31-17-33-28\n",
      "Endpoint arn:  arn:aws:sagemaker:us-west-2:662235870471:endpoint/sst2-text-classification-ep-2022-10-31-17-33-28\n"
     ]
    }
   ],
   "source": [
    "# create endpoint\n",
    "# ... endpoints console: https://console.aws.amazon.com/sagemaker/home?#/endpoints\n",
    "endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(endpoint_response)\n",
    "\n",
    "print('Endpoint name: {}'.format(endpoint_name))\n",
    "print('Endpoint arn:  {}'.format(endpoint_response['EndpointArn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '67c2b543-58ac-4305-8fd5-e5d286acece6', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '67c2b543-58ac-4305-8fd5-e5d286acece6', 'x-amzn-invoked-production-variant': 'AllTraffic', 'date': 'Mon, 31 Oct 2022 18:09:40 GMT', 'content-type': 'application/json', 'content-length': '48'}, 'RetryAttempts': 0}, 'ContentType': 'application/json', 'InvokedProductionVariant': 'AllTraffic', 'Body': <botocore.response.StreamingBody object at 0x7ff121c9e6a0>}\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.9968578815460205}]\n"
     ]
    }
   ],
   "source": [
    "# WAIT FOR ENDPOINT TO BE \"IN SERVICE\" BEFORE PROCEEDING WITH THIS STEP\n",
    "\n",
    "# invoke endpoint by endpoint name\n",
    "import json\n",
    "sm_runtime = session.client(\"sagemaker-runtime\", region_name=region_name)\n",
    "\n",
    "content_type = \"application/json\"\n",
    "\n",
    "# specify \"Inputs\"\n",
    "data = {\n",
    "   \"inputs\": \"I love Amazon SageMaker Studio Lab!\"\n",
    "}\n",
    "\n",
    "response = sm_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=content_type,\n",
    "    Body=json.dumps(data)\n",
    ")\n",
    "print(response)\n",
    "print(response[\"Body\"].read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up: uncomment the following lines\n",
    "#sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "#sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "#sm_client.delete_model(ModelName=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build api\n",
    "# !cd sm_api/\n",
    "# !sam build\n",
    "# !sam deploy --guided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Useful Resources:__\n",
    "\n",
    "* [Real-time or Persistent Endpoint](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints.html)\n",
    "\n",
    "* [Serverless Endpoint](https://docs.aws.amazon.com/sagemaker/latest/dg/serverless-endpoints-create.html)\n",
    "\n",
    "* [Use PyTorch with Amazon SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/pytorch.html)\n",
    "\n",
    "* [Deploy a Trained PyTorch Model Example](https://sagemaker-examples.readthedocs.io/en/latest/frameworks/pytorch/get_started_mnist_deploy.html)\n",
    "\n",
    "* [Video walk-through of deploying a trained PyTorch Model](https://www.youtube.com/watch?v=ZrhUgjnDW8c)\n",
    "\n",
    "* [Adding Custom Inference Scripts To SageMaker](https://aws.plainenglish.io/adding-custom-inference-scripts-to-amazon-sagemaker-2208c3332510)\n",
    "\n",
    "__Create model file in S3:__\n",
    "\n",
    "[Creating endpoint using PyTorch model trained somewhere else.](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#bring-your-own-model) Typically, you save a PyTorch model as a file with extension `.pt` or `.pth`\n",
    "* Write an inference script.\n",
    "    * Save the inference script in the same folder where you saved your PyTorch model. Pass the filename of the inference script as the `entry_point` parameter when you create the `PyTorchModel` object.\n",
    "* Create the directory structure for your model files.\n",
    "```\n",
    "| my_model \n",
    "|   |--model.pth \n",
    "|   \n",
    "|   code \n",
    "|       |--inference.py \n",
    "|       |--requirements.txt\n",
    "```\n",
    "* Create the `PyTorchModel` object, and then call its `deploy()` method to deploy your model for inference. The `PyTorchModel` constructor packs files into a `tar.gz` file and uploads it to S3.\n",
    "    \n",
    "    ```python\n",
    "    from sagemaker import get_execution_role\n",
    "    role = get_execution_role()\n",
    "\n",
    "    pytorch_model = PyTorchModel(model_data='s3://my-bucket/my-path/model.tar.gz', \n",
    "                                 role=role,\n",
    "                                 entry_point='inference.py')\n",
    "\n",
    "    predictor = pytorch_model.deploy(instance_type='ml.c4.xlarge', initial_instance_count=1)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('../../deepfm/FuxiCTR-main/')\n",
    "import fuxictr\n",
    "fuxictr.__version__\n",
    "from fuxictr.pytorch.models import DeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"DeepFM_all_feature.model\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_scripted.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.8/site-packages/torch/jit/_serialization.py:81\u001b[0m, in \u001b[0;36msave\u001b[0;34m(m, f, _extra_files)\u001b[0m\n\u001b[1;32m     79\u001b[0m     _extra_files \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, pathlib\u001b[38;5;241m.\u001b[39mPath):\n\u001b[0;32m---> 81\u001b[0m     \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m(f, _extra_files\u001b[38;5;241m=\u001b[39m_extra_files)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     ret \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39msave_to_buffer(_extra_files\u001b[38;5;241m=\u001b[39m_extra_files)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "torch.jit.save(model, 'model_scripted.pt') # Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.jit import save"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
