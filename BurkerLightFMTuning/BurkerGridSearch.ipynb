{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cody\\anaconda3\\envs\\lightfm\\lib\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Code from Carolina's notebook \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import json\n",
    "philly_bus = pd.read_feather('../FilteredData/business_philly.feather')\n",
    "philly_reviews = pd.read_feather('../FilteredData/review_philly.feather')\n",
    "philly_users = pd.read_feather('../FilteredData/user_philly.feather')\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k,auc_score,reciprocal_rank\n",
    "from lightfm.data import Dataset\n",
    "from lightfm import LightFM, cross_validation\n",
    "df = philly_reviews.groupby('user_id')['stars'].mean()\n",
    "users = pd.merge(philly_users, df, on=['user_id'], how='left')\n",
    "bins = [0, 0.9999999, 1.9999999, 2.9999999, 3.9999999, 4.9999999, 5]\n",
    "labels = [\"0\",\"1\", \"2\", \"3\",\"4\", \"5\"]\n",
    "users[\"star_bin\"] = pd.cut(users['stars'], bins=bins, labels=labels)\n",
    "reviews_only = philly_reviews[[\"user_id\", \"business_id\", \"stars\"]]\n",
    "#unique user features\n",
    "user_f = []\n",
    "user_col = ['star_bin']*len(users['star_bin'].unique()) \n",
    "user_unique_list = list(users['star_bin'].unique())\n",
    "# col = ['review_count']*len(users['review_count'].unique()) + ['useful']*len(users['useful'].unique()) + ['funny']*len(users['funny'].unique()) + ['cool']*len(users['cool'].unique())\n",
    "# unique_list = list(users['review_count'].unique()) + list(users['useful'].unique()) + list(users['funny'].unique()) + list(users['cool'].unique())\n",
    "\n",
    "\n",
    "for x,y in zip(user_col, user_unique_list):\n",
    "    res = str(x)+ \":\" +str(y)\n",
    "    user_f.append(res)\n",
    "\n",
    "item_f = []\n",
    "item_col = ['stars']*len(philly_bus['stars'].unique()) + ['postal_code']*len(philly_bus['postal_code'].unique())\n",
    "item_unique_list = list(philly_bus['stars'].unique()) + list(philly_bus['postal_code'].unique())\n",
    "\n",
    "for x,y in zip(item_col, item_unique_list):\n",
    "    res = str(x)+ \":\" +str(y)\n",
    "    item_f.append(res)\n",
    "dataset1 = Dataset()\n",
    "dataset1.fit(\n",
    "        philly_reviews['user_id'].unique(), # all the users\n",
    "        philly_reviews['business_id'].unique(), # all the items\n",
    "        user_features = user_f, # additional user features\n",
    "        item_features = item_f #additional item features\n",
    ")\n",
    "(interactions, weights) = dataset1.build_interactions([(x[0], x[1], x[2]) for x in reviews_only.values])\n",
    "train, test = cross_validation.random_train_test_split(interactions, test_percentage=0.25, random_state=np.random.RandomState(42))\n",
    "model = LightFM()\n",
    "model.fit(train,\n",
    "      epochs=30,\n",
    "      num_threads=4)\n",
    "from lightfm.evaluation import auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample training set down to 10% of the original size\n",
    "train_small, test_small = cross_validation.random_train_test_split(interactions, test_percentage=0.25, random_state=np.random.RandomState(42))\n",
    "_, train_tiny = cross_validation.random_train_test_split(train_small, test_percentage=0.1, random_state=np.random.RandomState(42))\n",
    "# Check that it works still \n",
    "# model = LightFM()\n",
    "# model.fit(train_tiny,\n",
    "#         epochs=30,\n",
    "#         num_threads=4)\n",
    "# test_auc = auc_score(model,\n",
    "#                         test_small,\n",
    "#                           ).mean()\n",
    "# print('Hybrid training set AUC: %s' % test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to tune\n",
    "epochs = [10, 20, 30] # number of epochs\n",
    "no_components = [5, 10, 20] # Dimensionality of the latent feature vectors\n",
    "loss_func = ['warp', 'bpr', 'logistic'] # Loss function\n",
    "learning_rate = [0.001, 0.01, 0.1] # Adagrad learning rate\n",
    "random_state = [42] # Random state\n",
    "# Create a dictionary of all the parameter options\n",
    "params = {'epochs': epochs,\n",
    "            'no_components': no_components,\n",
    "            'loss': loss_func,\n",
    "            'learning_rate': learning_rate,\n",
    "            'random_state': random_state}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create, train, and evaluate a model\n",
    "def create_model(train, test, epochs, no_components, loss_func, learning_rate, random_state):\n",
    "    model = LightFM(learning_rate=learning_rate, loss=loss_func, no_components=no_components, random_state=random_state)\n",
    "    model.fit(train,\n",
    "              epochs=epochs,\n",
    "              num_threads=4)\n",
    "    test_auc = auc_score(model,\n",
    "                         test,\n",
    "                         ).mean()\n",
    "    # Write params and AUC to file\n",
    "    file_name = f'Epochs_{epochs}_Components_{no_components}_Loss_{loss_func}_LearningRate_{learning_rate}_RandomState_{random_state}.txt'\n",
    "    with open(file_name, 'w') as f:\n",
    "        f.write(f'Epochs: {epochs}, Components: {no_components}, Loss: {loss_func}, Learning Rate: {learning_rate}, Random State: {random_state}, AUC: {test_auc}')\n",
    "    return test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid to search over with all combinations of parameters\n",
    "from itertools import product\n",
    "grid = list(product(epochs, no_components, loss_func, learning_rate, random_state))\n",
    "# Create list to store results\n",
    "results = []\n",
    "# Loop through each combination of parameters\n",
    "# Using multiprocessing to speed up the process\n",
    "from multiprocessing import Pool\n",
    "with Pool(16) as p:\n",
    "    for result in p.starmap(create_model, [(train_tiny, train_tiny, *x) for x in grid[0:2]]):\n",
    "        results.append(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('lightfm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6edbf9c204372b020a7874346a2b27de119d96e7d485f9c4895dbe57280a01f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
